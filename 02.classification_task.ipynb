{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_data\n",
    "from src.data import get_image_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (224,224)\n",
    "model_type = 'Mobilenet'\n",
    "bw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model_folder = f\"./data/models/mobilnet/\"\n",
    "ignore_file = '.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_prefix = './data/images/class_test/'\n",
    "test_paths = os.listdir(dir_prefix)\n",
    "if ignore_file in test_paths:\n",
    "    idx = test_paths.index(ignore_file)\n",
    "    test_paths.pop(idx)\n",
    "    \n",
    "test_paths = sorted(test_paths)\n",
    "test_images = np.array([get_image_value(os.path.join(dir_prefix, i), dim, bw, model_type) for i in test_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for file in test_paths:\n",
    "    if 'f' in file:\n",
    "        test_labels.append(0)\n",
    "    else:\n",
    "        test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Value Counts\n",
      "0    367\n",
      "1    309\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_paths, train_labels = get_data('train')\n",
    "train_images = np.array([get_image_value(i, dim, bw, model_type) for i in train_paths])\n",
    "train_dict = dict(images = train_images, labels = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Value Counts\n",
      "1    162\n",
      "0     62\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "valid_paths, valid_labels = get_data('valid')\n",
    "valid_images = np.array([get_image_value(i, dim, bw, model_type) for i in valid_paths])\n",
    "valid_dict = dict(images = valid_images, labels = valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_paths, test_labels = get_data('test')\n",
    "#test_images = np.array([get_image_value(i, dim, bw, model_type) for i in test_paths])\n",
    "#test_dict = dict(images = test_images, labels = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/images/syn/'\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "learing_rate = 5e-4\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  f\"{data_dir}/training\",\n",
    "  #validation_split=0.2,\n",
    "  #subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  f\"{data_dir}/validation\",\n",
    "  #validation_split=0.2,\n",
    "  #subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_images\n",
    "y_train = train_labels\n",
    "x_valid = valid_images\n",
    "y_valid = valid_labels\n",
    "x_test = test_images\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "43/43 [==============================] - 13s 197ms/step - loss: 0.7341 - accuracy: 0.5612 - val_loss: 0.6626 - val_accuracy: 0.5312\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66263, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.5577 - accuracy: 0.7442 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66263 to 0.54874, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.5126 - accuracy: 0.7385 - val_loss: 0.6036 - val_accuracy: 0.5938\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.54874\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.4059 - accuracy: 0.8229 - val_loss: 0.4317 - val_accuracy: 0.8281\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54874 to 0.43168, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.3838 - accuracy: 0.8095 - val_loss: 0.4634 - val_accuracy: 0.7969\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43168\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.3918 - accuracy: 0.8182 - val_loss: 0.4288 - val_accuracy: 0.7266\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43168 to 0.42883, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.3380 - accuracy: 0.8355 - val_loss: 0.4073 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42883 to 0.40728, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 6s 140ms/step - loss: 0.3547 - accuracy: 0.8297 - val_loss: 0.3649 - val_accuracy: 0.8359\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.40728 to 0.36487, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.3227 - accuracy: 0.8643 - val_loss: 0.3551 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36487 to 0.35509, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.2971 - accuracy: 0.8839 - val_loss: 0.3102 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.35509 to 0.31022, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.3238 - accuracy: 0.8522 - val_loss: 0.2565 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.31022 to 0.25652, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.2850 - accuracy: 0.8945 - val_loss: 0.2713 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25652\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.2596 - accuracy: 0.8870 - val_loss: 0.2611 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25652\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.2375 - accuracy: 0.8957 - val_loss: 0.3418 - val_accuracy: 0.7969\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25652\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.2446 - accuracy: 0.8860 - val_loss: 0.2637 - val_accuracy: 0.8828\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25652\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.2862 - accuracy: 0.8800 - val_loss: 0.2313 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.25652 to 0.23130, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.2053 - accuracy: 0.9109 - val_loss: 0.2708 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23130\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.2528 - accuracy: 0.8795 - val_loss: 0.2668 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.23130\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.2159 - accuracy: 0.9148 - val_loss: 0.2502 - val_accuracy: 0.8984\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23130\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.2074 - accuracy: 0.9154 - val_loss: 0.3257 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.23130\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.3143 - accuracy: 0.8670 - val_loss: 0.2866 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.23130\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 6s 140ms/step - loss: 0.2194 - accuracy: 0.9078 - val_loss: 0.2636 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.23130\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.2172 - accuracy: 0.9100 - val_loss: 0.2489 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.23130\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1908 - accuracy: 0.9171 - val_loss: 0.2416 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.23130\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.2127 - accuracy: 0.9236 - val_loss: 0.2378 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.23130\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1985 - accuracy: 0.9264 - val_loss: 0.2277 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23130 to 0.22769, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1987 - accuracy: 0.9134 - val_loss: 0.2343 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22769\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.2060 - accuracy: 0.9063 - val_loss: 0.2348 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.22769\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.1631 - accuracy: 0.9418 - val_loss: 0.2223 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22769 to 0.22229, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1844 - accuracy: 0.9296 - val_loss: 0.2214 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22229 to 0.22140, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1624 - accuracy: 0.9451 - val_loss: 0.2225 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.22140\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.1889 - accuracy: 0.9162 - val_loss: 0.2303 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.22140\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.1427 - accuracy: 0.9404 - val_loss: 0.2274 - val_accuracy: 0.8984\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.22140\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1729 - accuracy: 0.9191 - val_loss: 0.2179 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.22140 to 0.21791, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.1827 - accuracy: 0.9286 - val_loss: 0.2145 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.21791 to 0.21450, saving model to ./data/models/mobilnet/mobilenet_batch16_lr_0.0005_.h5\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.1594 - accuracy: 0.9503 - val_loss: 0.2164 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.21450\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.1685 - accuracy: 0.9261 - val_loss: 0.2253 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.21450\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1507 - accuracy: 0.9494 - val_loss: 0.2177 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.21450\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1730 - accuracy: 0.9209 - val_loss: 0.2156 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.21450\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.1826 - accuracy: 0.9142 - val_loss: 0.2210 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.21450\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.1692 - accuracy: 0.9461 - val_loss: 0.2211 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.21450\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.1401 - accuracy: 0.9611 - val_loss: 0.2191 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.21450\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.1750 - accuracy: 0.9224 - val_loss: 0.2189 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.21450\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.1850 - accuracy: 0.9321 - val_loss: 0.2175 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.21450\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.2007 - accuracy: 0.9123 - val_loss: 0.2178 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.21450\n"
     ]
    }
   ],
   "source": [
    "save_file_name = os.path.join(class_model_folder,f'mobilenet_batch{batch_size}_lr_{learing_rate}_.h5')\n",
    "model = MobileNet(#input_shape = (224,224,3),\n",
    "                  train_data=(x_train, y_train),\n",
    "                  valid_data=(x_test, y_test),\n",
    "                  lr=learing_rate,\n",
    "                  batch_size=batch_size,\n",
    "                  model_save_dir=save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cls_model_list = os.listdir(class_model_folder)\n",
    "if ignore_file in cls_model_list:\n",
    "    idx = cls_model_list.index(ignore_file)\n",
    "    cls_model_list.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name : mobilenet_batch32_lr2e4_val_loss_0.18656.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch8_lr_0.0005_val_loss_0.19687.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch16_lr2e4_val_loss_0.18929.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch64_lr1e4.h5, Acc : 0.81\n",
      "Model name : mobilenet_batch64_lr_2e5.h5, Acc : 0.88\n",
      "Model name : mobilenet_batch16_lr_0.0005_val_loss_0.2328.h5, Acc : 0.92\n",
      "Model name : mobilenet_batch16_lr_0.0005_.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch16_lr_5e4_val_loss_0.17087.h5, Acc : 0.95\n",
      "Model name : mobilenet_batch16_lr1e4_val_loss_0.275.h5, Acc : 0.88\n",
      "Model name : mobilenet_batch16_lr_0.001_val_loss_0.24776.h5, Acc : 0.94\n"
     ]
    }
   ],
   "source": [
    "test_output_list = {}\n",
    "for model_file in cls_model_list:\n",
    "    model = tf.keras.models.load_model(os.path.join(class_model_folder, model_file))\n",
    "    pred = model.predict(x_test)\n",
    "    df_tmp = pd.DataFrame()\n",
    "    df_tmp['file'] = test_paths\n",
    "    df_tmp['prob'] = np.reshape(pred, (len(pred), ))\n",
    "    df_tmp['pred'] = (df_tmp['prob']>0.5).astype(int)\n",
    "    df_tmp['true'] = y_test\n",
    "    print (f\"Model name : {model_file}, Acc : {accuracy_score(df_tmp['true'], df_tmp['pred']):.2f}\")\n",
    "    test_output_list[model_file] = df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>prob</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_00.jpg</td>\n",
       "      <td>0.586945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f_08.jpg</td>\n",
       "      <td>0.934553</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f_09.jpg</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f_39.jpg</td>\n",
       "      <td>0.653129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>f_41.jpg</td>\n",
       "      <td>0.525457</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>t_12.jpg</td>\n",
       "      <td>0.440546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>t_45.jpg</td>\n",
       "      <td>0.491136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file      prob  pred  true\n",
       "0    f_00.jpg  0.586945     1     0\n",
       "8    f_08.jpg  0.934553     1     0\n",
       "9    f_09.jpg  0.771903     1     0\n",
       "39   f_39.jpg  0.653129     1     0\n",
       "41   f_41.jpg  0.525457     1     0\n",
       "79   t_12.jpg  0.440546     0     1\n",
       "112  t_45.jpg  0.491136     0     1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_cls = \"mobilenet_batch16_lr_5e4_val_loss_0.17087.h5\"\n",
    "test_output_list[tmp_cls][test_output_list[tmp_cls]['pred']!=test_output_list[tmp_cls]['true']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>prob</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_00.jpg</td>\n",
       "      <td>0.577684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f_08.jpg</td>\n",
       "      <td>0.937778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f_09.jpg</td>\n",
       "      <td>0.893094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f_39.jpg</td>\n",
       "      <td>0.687143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>f_41.jpg</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>f_54.jpg</td>\n",
       "      <td>0.592520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>t_48.jpg</td>\n",
       "      <td>0.436313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>t_57.jpg</td>\n",
       "      <td>0.449710</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file      prob  pred  true\n",
       "0    f_00.jpg  0.577684     1     0\n",
       "8    f_08.jpg  0.937778     1     0\n",
       "9    f_09.jpg  0.893094     1     0\n",
       "39   f_39.jpg  0.687143     1     0\n",
       "41   f_41.jpg  0.589327     1     0\n",
       "54   f_54.jpg  0.592520     1     0\n",
       "115  t_48.jpg  0.436313     0     1\n",
       "124  t_57.jpg  0.449710     0     1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_cls = \"mobilenet_batch32_lr2e4_val_loss_0.18656.h5\"\n",
    "test_output_list[tmp_cls][test_output_list[tmp_cls]['pred']!=test_output_list[tmp_cls]['true']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
