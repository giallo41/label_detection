{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_data\n",
    "from src.data import get_image_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (224,224)\n",
    "model_type = 'Mobilenet'\n",
    "bw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model_folder = f\"./data/models/mobilnet/\"\n",
    "ignore_file = '.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_prefix = './data/images/class_test/'\n",
    "test_paths = os.listdir(dir_prefix)\n",
    "if ignore_file in test_paths:\n",
    "    idx = test_paths.index(ignore_file)\n",
    "    test_paths.pop(idx)\n",
    "    \n",
    "test_paths = sorted(test_paths)\n",
    "test_images = np.array([get_image_value(os.path.join(dir_prefix, i), dim, bw, model_type) for i in test_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for file in test_paths:\n",
    "    if 'f' in file:\n",
    "        test_labels.append(0)\n",
    "    else:\n",
    "        test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Value Counts\n",
      "0    354\n",
      "1    301\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_paths, train_labels = get_data('train')\n",
    "train_images = np.array([get_image_value(i, dim, bw, model_type) for i in train_paths])\n",
    "train_dict = dict(images = train_images, labels = train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID Value Counts\n",
      "1    162\n",
      "0     62\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "valid_paths, valid_labels = get_data('valid')\n",
    "valid_images = np.array([get_image_value(i, dim, bw, model_type) for i in valid_paths])\n",
    "valid_dict = dict(images = valid_images, labels = valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_paths, test_labels = get_data('test')\n",
    "#test_images = np.array([get_image_value(i, dim, bw, model_type) for i in test_paths])\n",
    "#test_dict = dict(images = test_images, labels = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/images/syn/'\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "learing_rate = 5e-4\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  f\"{data_dir}/training\",\n",
    "  #validation_split=0.2,\n",
    "  #subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  f\"{data_dir}/validation\",\n",
    "  #validation_split=0.2,\n",
    "  #subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655, 224, 224, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_images\n",
    "y_train = train_labels\n",
    "x_valid = valid_images\n",
    "y_valid = valid_labels\n",
    "x_test = test_images\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "save_file_name = os.path.join(class_model_folder,f'mobilenet_batch{batch_size}_lr_{learing_rate}_.h5')\n",
    "model = MobileNet(input_shape = (224,224,3),\n",
    "                  lr=learing_rate,\n",
    "                  batch_size=batch_size,\n",
    "                  model_save_dir=save_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "mobilenet_history = model.model.fit(train_ds,\n",
    "                                              epochs = 50, #model.epochs, \n",
    "                                              callbacks = [#model.early_stopping, \n",
    "                                                           model.model_checkpoint, \n",
    "                                                           model.lr_plat,\n",
    "                                                           model.tensorboard_history],\n",
    "                                              validation_data = valid_ds,\n",
    "                                              verbose= 1)\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "82/82 [==============================] - 12s 113ms/step - loss: 0.7139 - accuracy: 0.5864 - val_loss: 0.6173 - val_accuracy: 0.5469\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61728, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 2/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.5749 - accuracy: 0.6859 - val_loss: 0.6449 - val_accuracy: 0.5469\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.61728\n",
      "Epoch 3/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.4681 - accuracy: 0.7623 - val_loss: 0.4588 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.61728 to 0.45881, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 4/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.4344 - accuracy: 0.8054 - val_loss: 0.4130 - val_accuracy: 0.7891\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45881 to 0.41301, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 5/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.3970 - accuracy: 0.7977 - val_loss: 0.3331 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41301 to 0.33306, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 6/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.3931 - accuracy: 0.8372 - val_loss: 0.3919 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33306\n",
      "Epoch 7/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.3661 - accuracy: 0.8517 - val_loss: 0.3241 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33306 to 0.32411, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 8/200\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 0.3747 - accuracy: 0.8448 - val_loss: 0.3263 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32411\n",
      "Epoch 9/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2782 - accuracy: 0.8896 - val_loss: 0.3720 - val_accuracy: 0.7578\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32411\n",
      "Epoch 10/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.2427 - accuracy: 0.8748 - val_loss: 0.4564 - val_accuracy: 0.7031\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32411\n",
      "Epoch 11/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2850 - accuracy: 0.8983 - val_loss: 0.2671 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32411 to 0.26706, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 12/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2834 - accuracy: 0.8668 - val_loss: 0.2987 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26706\n",
      "Epoch 13/200\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 0.2283 - accuracy: 0.9140 - val_loss: 0.3129 - val_accuracy: 0.8203\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26706\n",
      "Epoch 14/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1881 - accuracy: 0.9135 - val_loss: 0.2510 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26706 to 0.25104, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 15/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2705 - accuracy: 0.8843 - val_loss: 0.2875 - val_accuracy: 0.8281\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25104\n",
      "Epoch 16/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1791 - accuracy: 0.9253 - val_loss: 0.2988 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25104\n",
      "Epoch 17/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2531 - accuracy: 0.9053 - val_loss: 0.2108 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25104 to 0.21083, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 18/200\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 0.2376 - accuracy: 0.9006 - val_loss: 0.2521 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.21083\n",
      "Epoch 19/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2294 - accuracy: 0.9111 - val_loss: 0.2568 - val_accuracy: 0.8984\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.21083\n",
      "Epoch 20/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1947 - accuracy: 0.9138 - val_loss: 0.2224 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.21083\n",
      "Epoch 21/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1620 - accuracy: 0.9492 - val_loss: 0.2531 - val_accuracy: 0.8828\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.21083\n",
      "Epoch 22/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2823 - accuracy: 0.9010 - val_loss: 0.2298 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.21083\n",
      "Epoch 23/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1726 - accuracy: 0.9259 - val_loss: 0.2140 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.21083\n",
      "Epoch 24/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1604 - accuracy: 0.9303 - val_loss: 0.2042 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21083 to 0.20418, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 25/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1586 - accuracy: 0.9405 - val_loss: 0.1969 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20418 to 0.19687, saving model to ./data/models/mobilnet/mobilenet_batch8_lr_0.0005_.h5\n",
      "Epoch 26/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1774 - accuracy: 0.9363 - val_loss: 0.1974 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.19687\n",
      "Epoch 27/200\n",
      "82/82 [==============================] - 6s 71ms/step - loss: 0.1427 - accuracy: 0.9553 - val_loss: 0.1970 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.19687\n",
      "Epoch 28/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2030 - accuracy: 0.9364 - val_loss: 0.2009 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.19687\n",
      "Epoch 29/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2410 - accuracy: 0.9075 - val_loss: 0.2071 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.19687\n",
      "Epoch 30/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1507 - accuracy: 0.9446 - val_loss: 0.2056 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.19687\n",
      "Epoch 31/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1618 - accuracy: 0.9467 - val_loss: 0.2050 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.19687\n",
      "Epoch 32/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1605 - accuracy: 0.9299 - val_loss: 0.2049 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.19687\n",
      "Epoch 33/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1403 - accuracy: 0.9457 - val_loss: 0.2045 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.19687\n",
      "Epoch 34/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1451 - accuracy: 0.9525 - val_loss: 0.2042 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.19687\n",
      "Epoch 35/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1922 - accuracy: 0.9364 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.19687\n",
      "Epoch 36/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1546 - accuracy: 0.9443 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.19687\n",
      "Epoch 37/200\n",
      "82/82 [==============================] - 6s 73ms/step - loss: 0.1290 - accuracy: 0.9468 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.19687\n",
      "Epoch 38/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1585 - accuracy: 0.9276 - val_loss: 0.2039 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.19687\n",
      "Epoch 39/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1789 - accuracy: 0.9323 - val_loss: 0.2039 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.19687\n",
      "Epoch 40/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1449 - accuracy: 0.9493 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.19687\n",
      "Epoch 41/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1868 - accuracy: 0.9349 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.19687\n",
      "Epoch 42/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1430 - accuracy: 0.9472 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.19687\n",
      "Epoch 43/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1344 - accuracy: 0.9478 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.19687\n",
      "Epoch 44/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1683 - accuracy: 0.9450 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.19687\n",
      "Epoch 45/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1526 - accuracy: 0.9435 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.19687\n",
      "Epoch 46/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1150 - accuracy: 0.9523 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.19687\n",
      "Epoch 47/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.2000 - accuracy: 0.9256 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.19687\n",
      "Epoch 48/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1122 - accuracy: 0.9643 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.19687\n",
      "Epoch 49/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1800 - accuracy: 0.9251 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.19687\n",
      "Epoch 50/200\n",
      "82/82 [==============================] - 6s 72ms/step - loss: 0.1596 - accuracy: 0.9321 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.19687\n",
      "Epoch 51/200\n",
      "82/82 [==============================] - 6s 74ms/step - loss: 0.1558 - accuracy: 0.9155 - val_loss: 0.2040 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.19687\n",
      "Epoch 52/200\n",
      " 3/82 [>.............................] - ETA: 5s - loss: 0.0841 - accuracy: 0.9861"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-bda18ce632c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                            model.tensorboard_history],\n\u001b[1;32m      7\u001b[0m                                               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#(x_valid, y_valid),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                               verbose= 1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mobilenet_history = model.model.fit_generator(augmentation.flow(x_train, y_train, batch_size = model.batch_size),\n",
    "                                              epochs = 200, #model.epochs, \n",
    "                                              callbacks = [#model.early_stopping, \n",
    "                                                           model.model_checkpoint, \n",
    "                                                           model.lr_plat,\n",
    "                                                           model.tensorboard_history],\n",
    "                                              validation_data = (x_test, y_test), #(x_valid, y_valid),\n",
    "                                              verbose= 1)\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cls_model_list = os.listdir(class_model_folder)\n",
    "if ignore_file in cls_model_list:\n",
    "    idx = cls_model_list.index(ignore_file)\n",
    "    cls_model_list.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name : mobilenet_batch32_lr2e4_val_loss_0.18656.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch8_lr_0.0005_val_loss_0.19687.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch16_lr2e4_val_loss_0.18929.h5, Acc : 0.94\n",
      "Model name : mobilenet_batch64_lr1e4.h5, Acc : 0.81\n",
      "Model name : mobilenet_batch64_lr_2e5.h5, Acc : 0.88\n",
      "Model name : mobilenet_batch16_lr_5e4_val_loss_0.17087.h5, Acc : 0.95\n",
      "Model name : mobilenet_val_loss_0.2768.h5, Acc : 0.91\n",
      "Model name : mobilenet_batch16_lr1e4_val_loss_0.275.h5, Acc : 0.88\n",
      "Model name : mobilenet_batch128_lr_5e5.h5, Acc : 0.82\n"
     ]
    }
   ],
   "source": [
    "test_output_list = {}\n",
    "for model_file in cls_model_list:\n",
    "    model = tf.keras.models.load_model(os.path.join(class_model_folder, model_file))\n",
    "    pred = model.predict(x_test)\n",
    "    df_tmp = pd.DataFrame()\n",
    "    df_tmp['file'] = test_paths\n",
    "    df_tmp['prob'] = np.reshape(pred, (len(pred), ))\n",
    "    df_tmp['pred'] = (df_tmp['prob']>0.5).astype(int)\n",
    "    df_tmp['true'] = y_test\n",
    "    print (f\"Model name : {model_file}, Acc : {accuracy_score(df_tmp['true'], df_tmp['pred']):.2f}\")\n",
    "    test_output_list[model_file] = df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>prob</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_00.jpg</td>\n",
       "      <td>0.586945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f_08.jpg</td>\n",
       "      <td>0.934553</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f_09.jpg</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f_39.jpg</td>\n",
       "      <td>0.653129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>f_41.jpg</td>\n",
       "      <td>0.525457</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>t_12.jpg</td>\n",
       "      <td>0.440546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>t_45.jpg</td>\n",
       "      <td>0.491136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file      prob  pred  true\n",
       "0    f_00.jpg  0.586945     1     0\n",
       "8    f_08.jpg  0.934553     1     0\n",
       "9    f_09.jpg  0.771903     1     0\n",
       "39   f_39.jpg  0.653129     1     0\n",
       "41   f_41.jpg  0.525457     1     0\n",
       "79   t_12.jpg  0.440546     0     1\n",
       "112  t_45.jpg  0.491136     0     1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_cls = \"mobilenet_batch16_lr_5e4_val_loss_0.17087.h5\"\n",
    "test_output_list[tmp_cls][test_output_list[tmp_cls]['pred']!=test_output_list[tmp_cls]['true']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>prob</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_00.jpg</td>\n",
       "      <td>0.577684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f_08.jpg</td>\n",
       "      <td>0.937778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f_09.jpg</td>\n",
       "      <td>0.893094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f_39.jpg</td>\n",
       "      <td>0.687143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>f_41.jpg</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>f_54.jpg</td>\n",
       "      <td>0.592520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>t_48.jpg</td>\n",
       "      <td>0.436313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>t_57.jpg</td>\n",
       "      <td>0.449710</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file      prob  pred  true\n",
       "0    f_00.jpg  0.577684     1     0\n",
       "8    f_08.jpg  0.937778     1     0\n",
       "9    f_09.jpg  0.893094     1     0\n",
       "39   f_39.jpg  0.687143     1     0\n",
       "41   f_41.jpg  0.589327     1     0\n",
       "54   f_54.jpg  0.592520     1     0\n",
       "115  t_48.jpg  0.436313     0     1\n",
       "124  t_57.jpg  0.449710     0     1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_cls = \"mobilenet_batch32_lr2e4_val_loss_0.18656.h5\"\n",
    "test_output_list[tmp_cls][test_output_list[tmp_cls]['pred']!=test_output_list[tmp_cls]['true']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
